{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3b29bcc0-1f3e-41ef-98ac-0f13a7ef0a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import chatgroq(cloud plateform for API Integration)\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e5a14d38-4ed1-4af4-a39e-9fd126cf3894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first person to land on the moon was Neil Armstrong. He stepped out of the lunar module Eagle and onto the moon's surface on July 20, 1969, during the Apollo 11 mission. Armstrong famously declared, \"That's one small step for man, one giant leap for mankind,\" as he became the first human to set foot on the moon.\n"
     ]
    }
   ],
   "source": [
    "#llm model integration\n",
    "llm = ChatGroq(\n",
    "    temperature=0, \n",
    "    groq_api_key='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', \n",
    "    model_name=\"llama-3.3-70b-versatile\"\n",
    ")\n",
    "#testing of llm model\n",
    "response = llm.invoke(\"The first person to land on moon was ...\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8dab9d2b-760c-4c1e-a287-2c073695b36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\nWebBaseLoader | ğŸ¦œï¸�ğŸ”— LangChain\\n\\n\\n\\n\\n\\n\\nSkip to main contentJoin us at  Interrupt: The Agent AI Conference by LangChain on May 13 & 14 in San Francisco!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1ğŸ’¬SearchProvidersAnthropicAWSGoogleHugging FaceMicrosoftOpenAIMoreProvidersAbsoAcreomActiveloop Deep LakeADS4GPTsAerospikeAgentQLAI21 LabsAimAINetworkAirbyteAirtableAlchemyAleph AlphaAlibaba CloudAnalyticDBAnnoyAnthropicAnyscaleApache Software FoundationApache DorisApifyAppleArangoDBArceeArcGISArgillaArizeArthurArxivAscendAskNewsAssemblyAIAstra DBAtlasAwaDBAWSAZLyricsAzure AIBAAIBagelBagelDBBaichuanBaiduBananaBasetenBeamBeautiful SoupBibTeXBiliBiliBittensorBlackboardbookend.aiBoxBrave SearchBreebs (Open Knowledge)BrowserbaseBrowserlessByteDanceCassandraCerebrasCerebriumAIChaindeskChromaClarifaiClearMLClickHouseClickUpCloudflareClovaCnosDBCogneeCogniSwitchCohereCollege ConfidentialCometConfident AIConfluenceConneryContextContextual AICouchbaseCozeCrateDBC TransformersCTranslate2CubeDappierDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODataheraldDedocDeepInfraDeeplakeDeepSeekDeepSparseDellDiffbotDingoDBDiscordDiscord (community loader)DocArrayDoclingDoctranDocugamiDocusaurusDriaDropboxDSPyDuckDBDuckDuckGo SearchE2BEden AIElasticsearchElevenLabsEmbedchainEpsillaEtherscanEverly AIEverNoteExaFacebook - MetaFalkorDBFaunaFiddlerFigmaFireCrawlFireworks AIFlyteFMP Data (Financial Data Prep)Forefront AIFriendli AIGeopandasGitGitBookGitHubGitLabGoldenGoodfireGoogleSerper - Google Search APIGooseAIGPT4AllGradientGraph RAGGraphsignalGrobidGroqGutenbergHacker NewsHazy ResearchHeliconeHologresHTML to textHuaweiHugging FaceHyperbrowserIBMIEIT SystemsiFixitiFlytekIMSDbInfinispan VSInfinityInfinoIntelIuguJaguarJavelin AI GatewayJenkinsJina AIJohnsnowlabsJoplinKDB.AIKineticaKoboldAIKonkoKoNLPYKÃ¹zuLabel StudiolakeFSLanceDBLangChain Decorators âœ¨LangFair: Use-Case Level LLM Bias and Fairness AssessmentsLanternLindormLinkupLiteLLMLlamaIndexLlama.cppLlamaEdgellamafileLLMonitorLocalAILog10MariTalkMarqoMediaWikiDumpMeilisearchMemcachedMetalMicrosoftMilvusMindsDBMinimaxMistralAIMLflow AI Gateway for LLMsMLflowMLXModalModelScopeModern TreasuryMomentoMongoDBMongoDB AtlasMotherduckMotÃ¶rheadMyScaleNAVERNeo4jNimbleNLPCloudNomicNotion DBNucliaNVIDIAObsidianOceanBaseOracle Cloud Infrastructure (OCI)OctoAIOllamaOntotext GraphDBOpenAIOpenGradientOpenLLMOpenSearchOpenWeatherMapOracleAI Vector SearchOutlineOutlinesPandasPaymanAIPebbloPermitPerplexityPetalsPostgres EmbeddingPGVectorPineconePipelineAIPipeshiftPortkeyPredibasePrediction GuardPremAISWI-PrologPromptLayerPsychicPubMedPullMd LoaderPygmalionAIPyMuPDF4LLMQdrantRAGatouillerank_bm25Ray ServeRebuffRedditRedisRemembrallReplicateRoamSema4 (fka Robocorp)RocksetRunhouseRWKV-4SalesforceSalute DevicesSambaNovaSAPScrapeGraph AISearchApiSearxNG Search APISemaDBSerpAPIShale ProtocolSingleStoreDBscikit-learnSlackSnowflakespaCySparkSparkLLMSpreedlySQLiteStack ExchangeStarRocksStochasticAIStreamlitStripeSupabase (Postgres)NebulaTableauTaigaTairTavilyTelegramTencentTensorFlow DatasetsTiDBTigerGraphTigrisTiloresTogether AI2MarkdownTranswarpTrelloTrubricsTruLensTwitterTypesenseUnstructuredUpstageupstashUpTrainUSearchValtheraVDMSVearchVectaraVespavliteVoyageAIWeights & BiasesWeights & Biases tracingWeights & Biases trackingWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriter, Inc.xAIXataXorbits Inference (Xinference)YahooYandexYeager.aiYellowbrick01.AIYouYouTubeZepZhipu AIZillizZoteroComponentsChat modelsChat modelsAbsoAI21 LabsAlibaba Cloud PAI EASAnthropic[Deprecated] Experimental Anthropic Tools WrapperAnyscaleAzureAIChatCompletionsModelAzure OpenAIAzure ML EndpointBaichuan ChatBaidu QianfanAWS BedrockCerebrasCloudflare Workers AICohereContextualAICoze ChatDappier AIDatabricksDeepInfraDeepSeekEden AIErnie Bot ChatEverlyAIFireworksChatFriendliGigaChatGoodfireGoogle AIGoogle Cloud Vertex AIGPTRouterGroqChatHuggingFaceIBM watsonx.aiJinaChatKineticaKonkoLiteLLMLiteLLM RouterLlama 2 ChatLlama APILlamaEdgeLlama.cppmaritalkMiniMaxMistralAIMLXModelScopeMoonshotNaverNVIDIA AI EndpointsChatOCIModelDeploymentOCIGenAIChatOctoAIOllamaOpenAIOutlinesPerplexityPipeshiftChatPredictionGuardPremAIPromptLayer ChatOpenAIRekaSambaNovaCloudSambaStudioSnowflake CortexsolarSparkLLM ChatNebula (Symbl.ai)Tencent HunyuanTogetherTongyi QwenUpstagevLLM ChatVolc Enging MaasChat WriterxAIXinferenceYandexGPTChatYIYuan2.0ZHIPU AIRetrieversRetrieversActiveloop Deep MemoryAmazon KendraArceeArxivAskNewsAzure AI SearchBedrock (Knowledge Bases)BM25BoxBREEBS (Open Knowledge)ChaindeskChatGPT pluginCogneeCohere rerankerCohere RAGDappierDocArrayDriaElasticSearch BM25ElasticsearchEmbedchainFlashRank rerankerFleet AI ContextGoogle DriveGoogle Vertex AI SearchGraph RAGIBM watsonx.aiJaguarDB Vector DatabaseKay.aiKinetica Vectorstore based RetrieverkNNLinkupSearchRetrieverLLMLingua Document CompressorLOTR (Merger Retriever)MetalMilvus Hybrid SearchNanoPQ (Product Quantization)needleNimbleOutlinePermitPinecone Hybrid SearchPubMedQdrant Sparse VectorRAGatouilleRePhraseQueryRememberizerSEC filingSelf-querying retrieversSingleStoreDBSVMTavilySearchAPITF-IDF**NeuralDB**VespaWikipediaYou.comZep CloudZep Open SourceZilliz Cloud PipelineZoteroTools/ToolkitsToolsADS4GPTsAgentQLAINetwork ToolkitAlpha VantageAmadeus ToolkitApify ActorArXivAskNewsAWS LambdaAzure AI Services ToolkitAzure Cognitive Services ToolkitAzure Container Apps dynamic sessionsShell (bash)Bearly Code InterpreterBing SearchBrave SearchCassandra Database ToolkitCDPChatGPT PluginsClickUp ToolkitCogniswitch ToolkitConnery Toolkit and ToolsDall-E Image GeneratorDappierDatabricks Unity Catalog (UC)DataForSEODataheraldDuckDuckGo SearchDiscordE2B Data AnalysisEden AIElevenLabs Text2SpeechExa SearchFile SystemFinancialDatasets ToolkitFMP DataGithub ToolkitGitlab ToolkitGmail ToolkitGolden QueryGoogle BooksGoogle Cloud Text-to-SpeechGoogle DriveGoogle FinanceGoogle ImagenGoogle JobsGoogle LensGoogle PlacesGoogle ScholarGoogle SearchGoogle SerperGoogle TrendsGradioGraphQLHuggingFace Hub ToolsHuman as a toolIFTTT WebHooksInfobipIonic Shopping ToolJenkinsJina SearchJira ToolkitJSON ToolkitLemon AgentLinkupSearchToolMemorizeMojeek SearchMultiOn ToolkitNASA ToolkitNuclia UnderstandingNVIDIA Riva: ASR and TTSOffice365 ToolkitOpenAPI ToolkitNatural Language API ToolkitsOpenGradientOpenWeatherMapOracle AI Vector Search: Generate SummaryPandas DataframePassio NutritionAIPaymanAIPermitPlayWright Browser ToolkitPolygon IO Toolkit and ToolsPowerBI ToolkitPrologPubMedPython REPLReddit SearchRequests ToolkitRiza Code InterpreterRobocorp ToolkitSalesforceSceneXplainScrapeGraphSearchApiSearxNG SearchSemantic Scholar API ToolSerpAPISlack ToolkitSpark SQL ToolkitSQLDatabase ToolkitStackExchangeSteam ToolkitStripeTableauTaigaTavily ExtractTavily SearchTiloresTwilioUpstageValtheraWikidataWikipediaWolfram AlphaWriter ToolsYahoo Finance NewsYou.com SearchYouTubeZapier Natural Language ActionsZenGuard AIDocument loadersDocument loadersacreomAgentQLLoaderAirbyteLoaderAirbyte CDK (Deprecated)Airbyte Gong (Deprecated)Airbyte Hubspot (Deprecated)Airbyte JSON (Deprecated)Airbyte Salesforce (Deprecated)Airbyte Shopify (Deprecated)Airbyte Stripe (Deprecated)Airbyte Typeform (Deprecated)Airbyte Zendesk Support (Deprecated)AirtableAlibaba Cloud MaxComputeAmazon TextractApify DatasetArcGISArxivLoaderAssemblyAI Audio TranscriptsAstraDBAsync ChromiumAsyncHtmlAthenaAWS S3 DirectoryAWS S3 FileAZLyricsAzure AI DataAzure Blob Storage ContainerAzure Blob Storage FileAzure AI Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBoxBrave SearchBrowserbaseBrowserlessBSHTMLLoaderCassandraChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCouchbaseCSVCube Semantic LayerDatadog LogsDedocDiffbotDiscordDoclingDocugamiDocusaurusDropboxDuckDBEmailEPubEtherscanEverNoteexample_dataFacebook ChatFaunaFigmaFireCrawlGeopandasGitGitBookGitHubGlue CatalogGoogle AlloyDB for PostgreSQLGoogle BigQueryGoogle BigtableGoogle Cloud SQL for SQL serverGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle Firestore in Datastore ModeGoogle DriveGoogle El Carro for Oracle WorkloadsGoogle Firestore (Native Mode)Google Memorystore for RedisGoogle SpannerGoogle Speech-to-Text Audio TranscriptsGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetHyperbrowserLoaderiFixitImagesImage captionsIMSDbIuguJoplinJSONLoaderJupyter NotebookKineticalakeFSLangSmithLarkSuite (FeiShu)LLM SherpaMastodonMathPixPDFLoaderMediaWiki DumpMerge Documents LoadermhtmlMicrosoft ExcelMicrosoft OneDriveMicrosoft OneNoteMicrosoft PowerPointMicrosoft SharePointMicrosoft WordNear BlockchainModern TreasuryMongoDBNeedle Document LoaderNews URLNotion DB 2/2NucliaObsidianOpen Document Format (ODT)Open City DataOracle Autonomous DatabaseOracle AI Vector Search: Document ProcessingOrg-modePandas DataFrameparsersPDFMinerLoaderPDFPlumberPebblo Safe DocumentLoaderPolars DataFrameDell PowerScale Document LoaderPsychicPubMedPullMdLoaderPyMuPDFLoaderPyMuPDF4LLMPyPDFDirectoryLoaderPyPDFium2LoaderPyPDFLoaderPySparkQuipReadTheDocs DocumentationRecursive URLRedditRoamRocksetrspaceRSS FeedsRSTscrapflyScrapingAntSitemapSlackSnowflakeSource CodeSpiderSpreedlyStripeSubtitleSurrealDBTelegramTencent COS DirectoryTencent COS FileTensorFlow DatasetsTiDB2MarkdownTOMLTrelloTSVTwitterUnstructuredUnstructuredMarkdownLoaderUnstructuredPDFLoaderUpstageURLVsdxWeatherWebBaseLoaderWhatsApp ChatWikipediaUnstructuredXMLLoaderXorbits Pandas DataFrameYouTube audioYouTube transcriptsYoutubeLoaderDLYuqueZeroxPDFLoaderVector storesVector storesActiveloop Deep LakeAerospikeAlibaba Cloud OpenSearchAnalyticDBAnnoyApache DorisApertureDBAstra DB Vector StoreAtlasAwaDBAzure Cosmos DB Mongo vCoreAzure Cosmos DB No SQLAzure AI SearchBagelBagelDBBaidu Cloud ElasticSearch VectorSearchBaidu VectorDBApache CassandraChromaClarifaiClickHouseCouchbaseDashVectorDatabricksDingoDBDocArray HnswSearchDocArray InMemorySearchAmazon Document DBDuckDBChina Mobile ECloud ElasticSearch VectorSearchElasticsearchEpsillaFaissFaiss (Async)FalkorDBVectorStoreGoogle AlloyDB for PostgreSQLGoogle BigQuery Vector SearchGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLFirestoreGoogle Memorystore for RedisGoogle SpannerGoogle Vertex AI Feature StoreGoogle Vertex AI Vector SearchHippoHologresInfinispanJaguar Vector DatabaseKDB.AIKineticaLanceDBLanternLindormLLMRailsManticoreSearch VectorStoreMarqoMeilisearchAmazon MemoryDBMilvusMomento Vector Index (MVI)MongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOceanbaseOpenSearchOracle AI Vector Search: Vector StorePathwayPostgres EmbeddingPGVecto.rsPGVectorPineconeQdrantRedisRelytRocksetSAP HANA Cloud Vector EngineScaNNSemaDBSingleStoreDBscikit-learnSQLiteVecSQLite-VSSSQLServerStarRocksSupabase (Postgres)SurrealDBTablestoreTairTencent Cloud VectorDBThirdAI NeuralDBTiDB VectorTigrisTileDBTimescale Vector (Postgres)TypesenseUpstash VectorUSearchValdVDMSVearchVectaraVespaviking DBvliteWeaviateXataYellowbrickZepZep CloudZillizEmbedding modelsEmbedding modelsAI21Aleph AlphaAnyscaleascendAwaDBAzureOpenAIBaichuan Text EmbeddingsBaidu QianfanBedrockBGE on Hugging FaceBookend AIClarifaiCloudflare Workers AIClova EmbeddingsCohereDashScopeDatabricksDeepInfraEDEN AIElasticsearchEmbaasERNIEFake EmbeddingsFastEmbed by QdrantFireworksGigaChatGoogle Generative AI EmbeddingsGoogle Vertex AIGPT4AllGradientHugging FaceIBM watsonx.aiInfinityInstruct Embeddings on Hugging FaceIPEX-LLM: Local BGE Embeddings on Intel CPUIPEX-LLM: Local BGE Embeddings on Intel GPUIntelÂ® Extension for Transformers Quantized Text EmbeddingsJinaJohn Snow LabsLASER Language-Agnostic SEntence Representations Embeddings by Meta AILindormLlama.cppllamafileLLMRailsLocalAIMiniMaxMistralAImodel2vecModelScopeMosaicMLNaverNLP CloudNomicNVIDIA NIMsOracle Cloud Infrastructure Generative AIOllamaOpenClipOpenAIOpenVINOEmbedding Documents using Optimized and Quantized EmbeddersOracle AI Vector Search: Generate EmbeddingsOVHcloudPinecone EmbeddingsPredictionGuardEmbeddingsPremAISageMakerSambaStudioSelf HostedSentence Transformers on Hugging FaceSolarSpaCySparkLLM Text EmbeddingsTensorFlow HubText Embeddings InferenceTextEmbed - Embedding Inference ServerTitan TakeoffTogether AIUpstageVolc EngineVoyage AIXorbits inference (Xinference)YandexGPTZhipuAIOtherComponentsDocument loadersWebBaseLoaderOn this pageWebBaseLoader\\nThis covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.\\nIf you don\\'t want to worry about website crawling, bypassing JS-blocking sites, and data cleaning, consider using FireCrawlLoader or the faster option SpiderLoader.\\nOverviewâ€‹\\nIntegration detailsâ€‹\\n\\nTODO: Fill in table features.\\nTODO: Remove JS support link if not relevant, otherwise ensure link is correct.\\nTODO: Make sure API reference links are correct.\\n\\nClassPackageLocalSerializableJS supportWebBaseLoaderlangchain_communityâœ…â�Œâ�Œ\\nLoader featuresâ€‹\\nSourceDocument Lazy LoadingNative Async SupportWebBaseLoaderâœ…âœ…\\nSetupâ€‹\\nCredentialsâ€‹\\nWebBaseLoader does not require any credentials.\\nInstallationâ€‹\\nTo use the WebBaseLoader you first need to install the langchain-community python package.\\n%pip install -qU langchain_community beautifulsoup4\\nInitializationâ€‹\\nNow we can instantiate our model object and load documents:\\nfrom langchain_community.document_loaders import WebBaseLoaderloader = WebBaseLoader(\"https://www.example.com/\")API Reference:WebBaseLoader\\nTo bypass SSL verification errors during fetching, you can set the \"verify\" option:\\nloader.requests_kwargs = {\\'verify\\':False}\\nInitialization with multiple pagesâ€‹\\nYou can also pass in a list of pages to load from.\\nloader_multiple_pages = WebBaseLoader(    [\"https://www.example.com/\", \"https://google.com\"])\\nLoadâ€‹\\ndocs = loader.load()docs[0]\\nDocument(metadata={\\'source\\': \\'https://www.example.com/\\', \\'title\\': \\'Example Domain\\', \\'language\\': \\'No language found.\\'}, page_content=\\'\\\\n\\\\n\\\\nExample Domain\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nExample Domain\\\\nThis domain is for use in illustrative examples in documents. You may use this\\\\n    domain in literature without prior coordination or asking for permission.\\\\nMore information...\\\\n\\\\n\\\\n\\\\n\\')\\nprint(docs[0].metadata)\\n{\\'source\\': \\'https://www.example.com/\\', \\'title\\': \\'Example Domain\\', \\'language\\': \\'No language found.\\'}\\nLoad multiple urls concurrentlyâ€‹\\nYou can speed up the scraping process by scraping and parsing multiple urls concurrently.\\nThere are reasonable limits to concurrent requests, defaulting to 2 per second.  If you aren\\'t concerned about being a good citizen, or you control the server you are scraping and don\\'t care about load, you can change the requests_per_second parameter to increase the max concurrent requests.  Note, while this will speed up the scraping process, but may cause the server to block you.  Be careful!\\n%pip install -qU  nest_asyncio# fixes a bug with asyncio and jupyterimport nest_asyncionest_asyncio.apply()\\nNote: you may need to restart the kernel to use updated packages.\\nloader = WebBaseLoader([\"https://www.example.com/\", \"https://google.com\"])loader.requests_per_second = 1docs = loader.aload()docs\\nFetching pages: 100%|###########################################################################| 2/2 [00:00<00:00,  8.28it/s]\\n[Document(metadata={\\'source\\': \\'https://www.example.com/\\', \\'title\\': \\'Example Domain\\', \\'language\\': \\'No language found.\\'}, page_content=\\'\\\\n\\\\n\\\\nExample Domain\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nExample Domain\\\\nThis domain is for use in illustrative examples in documents. You may use this\\\\n    domain in literature without prior coordination or asking for permission.\\\\nMore information...\\\\n\\\\n\\\\n\\\\n\\'), Document(metadata={\\'source\\': \\'https://google.com\\', \\'title\\': \\'Google\\', \\'description\\': \"Search the world\\'s information, including webpages, images, videos and more. Google has many special features to help you find exactly what you\\'re looking for.\", \\'language\\': \\'en\\'}, page_content=\\'GoogleSearch Images Maps Play YouTube News Gmail Drive More Â»Web History | Settings | Sign in\\\\xa0Advanced search5 ways Gemini can help during the HolidaysAdvertisingBusiness SolutionsAbout GoogleÂ© 2024 - Privacy - Terms  \\')]\\nLoading a xml file, or using a different BeautifulSoup parserâ€‹\\nYou can also look at SitemapLoader for an example of how to load a sitemap file, which is an example of using this feature.\\nloader = WebBaseLoader(    \"https://www.govinfo.gov/content/pkg/CFR-2018-title10-vol3/xml/CFR-2018-title10-vol3-sec431-86.xml\")loader.default_parser = \"xml\"docs = loader.load()docs\\n[Document(metadata={\\'source\\': \\'https://www.govinfo.gov/content/pkg/CFR-2018-title10-vol3/xml/CFR-2018-title10-vol3-sec431-86.xml\\'}, page_content=\\'\\\\n\\\\n10\\\\nEnergy\\\\n3\\\\n2018-01-01\\\\n2018-01-01\\\\nfalse\\\\nUniform test method for the measurement of energy efficiency of commercial packaged boilers.\\\\nÃ‚Â§ 431.86\\\\nSection Ã‚Â§ 431.86\\\\n\\\\nEnergy\\\\nDEPARTMENT OF ENERGY\\\\nENERGY CONSERVATION\\\\nENERGY EFFICIENCY PROGRAM FOR CERTAIN COMMERCIAL AND INDUSTRIAL EQUIPMENT\\\\nCommercial Packaged Boilers\\\\nTest Procedures\\\\n\\\\n\\\\n\\\\n\\\\nÂ§\\\\u2009431.86\\\\nUniform test method for the measurement of energy efficiency of commercial packaged boilers.\\\\n(a) Scope. This section provides test procedures, pursuant to the Energy Policy and Conservation Act (EPCA), as amended, which must be followed for measuring the combustion efficiency and/or thermal efficiency of a gas- or oil-fired commercial packaged boiler.\\\\n(b) Testing and Calculations. Determine the thermal efficiency or combustion efficiency of commercial packaged boilers by conducting the appropriate test procedure(s) indicated in Table 1 of this section.\\\\n\\\\nTable 1â€”Test Requirements for Commercial Packaged Boiler Equipment Classes\\\\n\\\\nEquipment category\\\\nSubcategory\\\\nCertified rated inputBtu/h\\\\n\\\\nStandards efficiency metric(Â§\\\\u2009431.87)\\\\n\\\\nTest procedure(corresponding to\\\\nstandards efficiency\\\\nmetric required\\\\nby Â§\\\\u2009431.87)\\\\n\\\\n\\\\n\\\\nHot Water\\\\nGas-fired\\\\nâ‰¥300,000 and â‰¤2,500,000\\\\nThermal Efficiency\\\\nAppendix A, Section 2.\\\\n\\\\n\\\\nHot Water\\\\nGas-fired\\\\n>2,500,000\\\\nCombustion Efficiency\\\\nAppendix A, Section 3.\\\\n\\\\n\\\\nHot Water\\\\nOil-fired\\\\nâ‰¥300,000 and â‰¤2,500,000\\\\nThermal Efficiency\\\\nAppendix A, Section 2.\\\\n\\\\n\\\\nHot Water\\\\nOil-fired\\\\n>2,500,000\\\\nCombustion Efficiency\\\\nAppendix A, Section 3.\\\\n\\\\n\\\\nSteam\\\\nGas-fired (all*)\\\\nâ‰¥300,000 and â‰¤2,500,000\\\\nThermal Efficiency\\\\nAppendix A, Section 2.\\\\n\\\\n\\\\nSteam\\\\nGas-fired (all*)\\\\n>2,500,000 and â‰¤5,000,000\\\\nThermal Efficiency\\\\nAppendix A, Section 2.\\\\n\\\\n\\\\n\\\\u2003\\\\n\\\\n>5,000,000\\\\nThermal Efficiency\\\\nAppendix A, Section 2.OR\\\\nAppendix A, Section 3 with Section 2.4.3.2.\\\\n\\\\n\\\\n\\\\nSteam\\\\nOil-fired\\\\nâ‰¥300,000 and â‰¤2,500,000\\\\nThermal Efficiency\\\\nAppendix A, Section 2.\\\\n\\\\n\\\\nSteam\\\\nOil-fired\\\\n>2,500,000 and â‰¤5,000,000\\\\nThermal Efficiency\\\\nAppendix A, Section 2.\\\\n\\\\n\\\\n\\\\u2003\\\\n\\\\n>5,000,000\\\\nThermal Efficiency\\\\nAppendix A, Section 2.OR\\\\nAppendix A, Section 3. with Section 2.4.3.2.\\\\n\\\\n\\\\n\\\\n*\\\\u2009Equipment classes for commercial packaged boilers as of July 22, 2009 (74 FR 36355) distinguish between gas-fired natural draft and all other gas-fired (except natural draft).\\\\n\\\\n(c) Field Tests. The field test provisions of appendix A may be used only to test a unit of commercial packaged boiler with rated input greater than 5,000,000 Btu/h.\\\\n[81 FR 89305, Dec. 9, 2016]\\\\n\\\\n\\\\nEnergy Efficiency Standards\\\\n\\\\n\\')]\\nLazy Loadâ€‹\\nYou can use lazy loading to only load one page at a time in order to minimize memory requirements.\\npages = []for doc in loader.lazy_load():    pages.append(doc)print(pages[0].page_content[:100])print(pages[0].metadata)\\n10Energy32018-01-012018-01-01falseUniform test method for the measurement of energy efficien{\\'source\\': \\'https://www.govinfo.gov/content/pkg/CFR-2018-title10-vol3/xml/CFR-2018-title10-vol3-sec431-86.xml\\'}\\nAsyncâ€‹\\npages = []async for doc in loader.alazy_load():    pages.append(doc)print(pages[0].page_content[:100])print(pages[0].metadata)\\nFetching pages: 100%|###########################################################################| 1/1 [00:00<00:00, 10.51it/s]``````output10Energy32018-01-012018-01-01falseUniform test method for the measurement of energy efficien{\\'source\\': \\'https://www.govinfo.gov/content/pkg/CFR-2018-title10-vol3/xml/CFR-2018-title10-vol3-sec431-86.xml\\'}\\nUsing proxiesâ€‹\\nSometimes you might need to use proxies to get around IP blocks. You can pass in a dictionary of proxies to the loader (and requests underneath) to use them.\\nloader = WebBaseLoader(    \"https://www.walmart.com/search?q=parrots\",    proxies={        \"http\": \"http://{username}:{password}:@proxy.service.com:6666/\",        \"https\": \"https://{username}:{password}:@proxy.service.com:6666/\",    },)docs = loader.load()\\nAPI referenceâ€‹\\nFor detailed documentation of all WebBaseLoader features and configurations head to the API reference: https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.web_base.WebBaseLoader.html\\nRelatedâ€‹\\n\\nDocument loader conceptual guide\\nDocument loader how-to guides\\nEdit this pageWas this page helpful?PreviousWeatherNextWhatsApp ChatOverviewIntegration detailsLoader featuresSetupCredentialsInstallationInitializationInitialization with multiple pagesLoadLoad multiple urls concurrentlyLoading a xml file, or using a different BeautifulSoup parserLazy LoadAsyncUsing proxiesAPI referenceRelatedCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright Â© 2025 LangChain, Inc.\\n\\n'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# webbaseloader helps to extract text from web pages \n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://python.langchain.com/docs/integrations/document_loaders/web_base/#loader-features\")\n",
    "page_data = loader.load().pop().page_content\n",
    "page_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ae3997a7-a71f-478b-bdc5-716213af301f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "    {\n",
      "        \"role\": \"Software Engineer\",\n",
      "        \"experience\": \"2-5 years\",\n",
      "        \"skills\": [\"Python\", \"Java\", \"C++\"],\n",
      "        \"description\": \"Design, develop, and test software applications\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"Data Scientist\",\n",
      "        \"experience\": \"5-10 years\",\n",
      "        \"skills\": [\"Machine Learning\", \"Data Analysis\", \"Statistics\"],\n",
      "        \"description\": \"Analyze and interpret complex data to inform business decisions\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"Product Manager\",\n",
      "        \"experience\": \"5-10 years\",\n",
      "        \"skills\": [\"Product Development\", \"Marketing\", \"Leadership\"],\n",
      "        \"description\": \"Develop and launch new products to drive business growth\"\n",
      "    }\n",
      "]\n",
      "```\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt template langchain helps to design json file prompts and extract useful information from webbaseloader file\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "prompt_extract = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "        ### SCRAPED TEXT FROM WEBSITE:\n",
    "        {page_data}\n",
    "        ### INSTRUCTION:\n",
    "        The scraped text is from the career's page of a website.\n",
    "        Your job is to extract the job postings and return them in JSON format containing the \n",
    "        following keys: `role`, `experience`, `skills` and `description`.\n",
    "        Only return the valid JSON.\n",
    "        ### VALID JSON (NO PREAMBLE):    \n",
    "        \"\"\"\n",
    ")\n",
    "\n",
    "chain_extract = prompt_extract | llm \n",
    "res = chain_extract.invoke(input={'page_data':page_data})\n",
    "print(res.content)\n",
    "type(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5c6ae0b7-4309-48e3-94b1-20f7daa291d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'Software Engineer', 'experience': '2-5 years', 'skills': ['Python', 'Java', 'C++'], 'description': 'Design, develop, and test software applications'}, {'role': 'Data Scientist', 'experience': '5-10 years', 'skills': ['Machine Learning', 'Data Analysis', 'Statistics'], 'description': 'Analyze and interpret complex data to inform business decisions'}, {'role': 'Product Manager', 'experience': '5-10 years', 'skills': ['Product Development', 'Marketing', 'Leadership'], 'description': 'Develop and launch new products to drive business growth'}]\n"
     ]
    }
   ],
   "source": [
    "# jsonoutputparser helps to make json file in list datatype to fetch data easily\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "json_parser = JsonOutputParser()\n",
    "json_res = json_parser.parse(res.content)\n",
    "type(json_res)\n",
    "print(json_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "47882cca-b873-4927-bf44-dea9a9b48f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Techstack</th>\n",
       "      <th>Links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>React, Node.js, MongoDB</td>\n",
       "      <td>https://example.com/react-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Angular,.NET, SQL Server</td>\n",
       "      <td>https://example.com/angular-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vue.js, Ruby on Rails, PostgreSQL</td>\n",
       "      <td>https://example.com/vue-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python, Django, MySQL</td>\n",
       "      <td>https://example.com/python-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Java, Spring Boot, Oracle</td>\n",
       "      <td>https://example.com/java-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Flutter, Firebase, GraphQL</td>\n",
       "      <td>https://example.com/flutter-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WordPress, PHP, MySQL</td>\n",
       "      <td>https://example.com/wordpress-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Magento, PHP, MySQL</td>\n",
       "      <td>https://example.com/magento-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>React Native, Node.js, MongoDB</td>\n",
       "      <td>https://example.com/react-native-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>iOS, Swift, Core Data</td>\n",
       "      <td>https://example.com/ios-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Android, Java, Room Persistence</td>\n",
       "      <td>https://example.com/android-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kotlin, Android, Firebase</td>\n",
       "      <td>https://example.com/kotlin-android-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Android TV, Kotlin, Android NDK</td>\n",
       "      <td>https://example.com/android-tv-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>iOS, Swift, ARKit</td>\n",
       "      <td>https://example.com/ios-ar-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cross-platform, Xamarin, Azure</td>\n",
       "      <td>https://example.com/xamarin-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Backend, Kotlin, Spring Boot</td>\n",
       "      <td>https://example.com/kotlin-backend-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Frontend, TypeScript, Angular</td>\n",
       "      <td>https://example.com/typescript-frontend-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Full-stack, JavaScript, Express.js</td>\n",
       "      <td>https://example.com/full-stack-js-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Machine Learning, Python, TensorFlow</td>\n",
       "      <td>https://example.com/ml-python-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DevOps, Jenkins, Docker</td>\n",
       "      <td>https://example.com/devops-portfolio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Techstack  \\\n",
       "0                React, Node.js, MongoDB   \n",
       "1               Angular,.NET, SQL Server   \n",
       "2      Vue.js, Ruby on Rails, PostgreSQL   \n",
       "3                  Python, Django, MySQL   \n",
       "4              Java, Spring Boot, Oracle   \n",
       "5             Flutter, Firebase, GraphQL   \n",
       "6                  WordPress, PHP, MySQL   \n",
       "7                    Magento, PHP, MySQL   \n",
       "8         React Native, Node.js, MongoDB   \n",
       "9                  iOS, Swift, Core Data   \n",
       "10       Android, Java, Room Persistence   \n",
       "11             Kotlin, Android, Firebase   \n",
       "12       Android TV, Kotlin, Android NDK   \n",
       "13                     iOS, Swift, ARKit   \n",
       "14        Cross-platform, Xamarin, Azure   \n",
       "15          Backend, Kotlin, Spring Boot   \n",
       "16         Frontend, TypeScript, Angular   \n",
       "17    Full-stack, JavaScript, Express.js   \n",
       "18  Machine Learning, Python, TensorFlow   \n",
       "19               DevOps, Jenkins, Docker   \n",
       "\n",
       "                                                Links  \n",
       "0                 https://example.com/react-portfolio  \n",
       "1               https://example.com/angular-portfolio  \n",
       "2                   https://example.com/vue-portfolio  \n",
       "3                https://example.com/python-portfolio  \n",
       "4                  https://example.com/java-portfolio  \n",
       "5               https://example.com/flutter-portfolio  \n",
       "6             https://example.com/wordpress-portfolio  \n",
       "7               https://example.com/magento-portfolio  \n",
       "8          https://example.com/react-native-portfolio  \n",
       "9                   https://example.com/ios-portfolio  \n",
       "10              https://example.com/android-portfolio  \n",
       "11       https://example.com/kotlin-android-portfolio  \n",
       "12           https://example.com/android-tv-portfolio  \n",
       "13               https://example.com/ios-ar-portfolio  \n",
       "14              https://example.com/xamarin-portfolio  \n",
       "15       https://example.com/kotlin-backend-portfolio  \n",
       "16  https://example.com/typescript-frontend-portfolio  \n",
       "17        https://example.com/full-stack-js-portfolio  \n",
       "18            https://example.com/ml-python-portfolio  \n",
       "19               https://example.com/devops-portfolio  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/my_portfolio.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "caee5534-7561-46be-8398-ccb5d09f28eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import chromadb a vector Database helps to detect and search query easily and have more features than normal database \n",
    "import uuid\n",
    "import chromadb\n",
    "\n",
    "client = chromadb.PersistentClient('vectorstore')\n",
    "collection = client.get_or_create_collection(name=\"portfolio\")\n",
    "\n",
    "if not collection.count():\n",
    "    for _, row in df.iterrows():\n",
    "        collection.add(documents=row[\"Techstack\"],\n",
    "                       metadatas={\"links\": row[\"Links\"]},\n",
    "                       ids=[str(uuid.uuid4())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0dd88648-0f05-46e5-b3b7-1f5793797188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'links': 'https://example.com/ml-python-portfolio'},\n",
       "  {'links': 'https://example.com/python-portfolio'}]]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing for functioning of chromadb\n",
    "links = collection.query(query_texts=['python'], n_results=2).get('metadatas', [])\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d53d85cf-deae-46f8-8c53-0cb28a2483a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'Software Engineer', 'experience': '2-5 years', 'skills': ['Python', 'Java', 'C++'], 'description': 'Design, develop, and test software applications'}, {'role': 'Data Scientist', 'experience': '5-10 years', 'skills': ['Machine Learning', 'Data Analysis', 'Statistics'], 'description': 'Analyze and interpret complex data to inform business decisions'}, {'role': 'Product Manager', 'experience': '5-10 years', 'skills': ['Product Development', 'Marketing', 'Leadership'], 'description': 'Develop and launch new products to drive business growth'}]\n"
     ]
    }
   ],
   "source": [
    "print(json_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bdd3909d-34a9-491f-b05a-55e8981e0b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python', 'Java', 'C++']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job = json_res[0]  # Access the first dictionary in the list\n",
    "skills = job['skills']\n",
    "skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0c149865-b2bb-4b1b-bda2-fe33c6b153b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Expert Software Engineering Solutions for Your Business\n",
      "\n",
      "Dear Hiring Manager,\n",
      "\n",
      "I came across your job posting for a Software Engineer with 2-5 years of experience in Python, Java, and C++. I'd like to introduce AtliQ, an AI & Software Consulting company that can help you find the perfect candidate or even provide a team of experts to design, develop, and test software applications tailored to your business needs.\n",
      "\n",
      "At AtliQ, we have a proven track record of empowering enterprises with customized solutions, resulting in scalability, process optimization, cost reduction, and increased overall efficiency. Our team of skilled software engineers has extensive experience in developing software applications using a range of programming languages, including Python, Java, and C++.\n",
      "\n",
      "I'd like to highlight some of our relevant portfolio work, which demonstrates our expertise in software development:\n",
      "- https://example.com/ml-python-portfolio (Machine Learning with Python)\n",
      "- https://example.com/python-portfolio (Python-based solutions)\n",
      "\n",
      "Our expertise in software development, combined with our AI capabilities, enables us to deliver cutting-edge solutions that meet the unique requirements of your business. Whether you're looking to build a new application or enhance an existing one, we're confident that our team can help you achieve your goals.\n",
      "\n",
      "If you're interested in learning more about how AtliQ can support your software engineering needs, I'd be happy to schedule a call to discuss further.\n",
      "\n",
      "Best regards,\n",
      "Mohan\n",
      "Business Development Executive\n",
      "AtliQ\n"
     ]
    }
   ],
   "source": [
    "prompt_email = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        ### JOB DESCRIPTION:\n",
    "        {job_description}\n",
    "        \n",
    "        ### INSTRUCTION:\n",
    "        You are Mohan, a business development executive at AtliQ. AtliQ is an AI & Software Consulting company dedicated to facilitating\n",
    "        the seamless integration of business processes through automated tools. \n",
    "        Over our experience, we have empowered numerous enterprises with tailored solutions, fostering scalability, \n",
    "        process optimization, cost reduction, and heightened overall efficiency. \n",
    "        Your job is to write a cold email to the client regarding the job mentioned above describing the capability of AtliQ \n",
    "        in fulfilling their needs.\n",
    "        Also add the most relevant ones from the following links to showcase Atliq's portfolio: {link_list}\n",
    "        Remember you are Mohan, BDE at AtliQ. \n",
    "        Do not provide a preamble.\n",
    "        ### EMAIL (NO PREAMBLE):\n",
    "        \n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "chain_email = prompt_email | llm\n",
    "res = chain_email.invoke({\"job_description\": str(job), \"link_list\": links})\n",
    "print(res.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
